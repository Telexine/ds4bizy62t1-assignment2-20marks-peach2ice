{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraby & Init url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# display progress bar (tqdm>=4.23.4 | pandas==0.24.0)\n",
    "from tqdm import tqdm_notebook as tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init request\n",
    "baseUrl = \"http://www.it.kmitl.ac.th/~teerapong/news_archive\"\n",
    "homeUrl = \"http://www.it.kmitl.ac.th/~teerapong/news_archive/index.html\"\n",
    "response = requests.get(homeUrl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Month URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse html\n",
    "soup = BeautifulSoup(response.text, \"html.parser\", from_encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create month url\n",
    "li_group = soup.findAll('li')\n",
    "month_url_group = [f\"{baseUrl}/{li.find('a')['href']}\" for li in li_group]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Article Properties "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: 1408\n",
      "Title: 1408\n",
      "Url: 1408\n"
     ]
    }
   ],
   "source": [
    "# use url each month to fetch article\n",
    "article_category = []\n",
    "article_title = []\n",
    "article_url = []\n",
    "\n",
    "# loop each month\n",
    "for month in month_url_group:\n",
    "    \n",
    "    # init soup\n",
    "    month_resp = requests.get(month);\n",
    "    soup = BeautifulSoup(month_resp.text, \"html.parser\", from_encoding=\"utf-8\")\n",
    "    \n",
    "    # append category\n",
    "    category_group = soup.findAll('td', {'class': 'category'});\n",
    "    for category in category_group:\n",
    "        # article category not available -> skip\n",
    "        if category.getText().strip() == \"N/A\": continue\n",
    "        article_category.append(category.getText().strip())\n",
    "        \n",
    "    # append title & url\n",
    "    title_group = soup.findAll('td', {'class': 'title'});\n",
    "    for title in title_group:\n",
    "        # article title not available -> skip\n",
    "        if title.getText().strip() == \"Article no longer available in archive\": continue\n",
    "        article_title.append(title.getText().strip())\n",
    "        article_url.append(f\"{baseUrl}/{title.find('a')['href']}\")\n",
    "\n",
    "        \n",
    "# display article properties length (check length is match)\n",
    "print(\"Category: \" + str(len(article_category)))\n",
    "print(\"Title: \" + str(len(article_title)))\n",
    "print(\"Url: \" + str(len(article_url)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Article Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e3d8eebf5a4927976e489890dd2999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Content: 100\n"
     ]
    }
   ],
   "source": [
    "# use articule url to fetch article content\n",
    "article_content = []\n",
    "\n",
    "# init progress bar\n",
    "with tqdm(total=len(my_list)) as pbar:\n",
    "    \n",
    "    # loop each article\n",
    "    for article in article_url[:100]:\n",
    "\n",
    "        article_resp = requests.get(article);\n",
    "        soup = BeautifulSoup(article_resp.text, \"html.parser\", from_encoding=\"utf-8\")\n",
    "        \n",
    "        current_content = []\n",
    "        \n",
    "        article_group = soup.findAll('p')\n",
    "        for content in article_group[:-1]:\n",
    "\n",
    "            # check <p> is empty?\n",
    "            if (content.text == \"\"): continue\n",
    "            current_content.append(content.text.rstrip(\"\\n\\r\"))\n",
    "\n",
    "        # join each <p> to raw string and append to article_content\n",
    "        article_content.append(''.join(current_content))\n",
    "        \n",
    "        # update progress bar\n",
    "        pbar.update(1)\n",
    "\n",
    "# display article content length\n",
    "print(\"Content: \" + str(len(article_content)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write article_title.txt\n",
    "with open(\"./datastore/article_title.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for row in article_title:\n",
    "        file.write(\"%s\\n\" % row)\n",
    "    file.close()\n",
    "    \n",
    "# write article_content.txt\n",
    "with open(\"./datastore/article_content.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for row in article_content:\n",
    "        file.write(\"%s\\n\" % row)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
